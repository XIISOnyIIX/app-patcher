version: '3.9'

services:
  backend:
    build:
      context: .
      dockerfile: Dockerfile.production
    restart: unless-stopped
    ports:
      - '${PORT:-4000}:4000'
    environment:
      - NODE_ENV=production
      - PORT=${PORT:-4000}
      - CORS_ORIGIN=${CORS_ORIGIN:-*}
      # Scraper configuration
      - SCRAPER_RATE_LIMIT_REQUESTS=${SCRAPER_RATE_LIMIT_REQUESTS:-10}
      - SCRAPER_RATE_LIMIT_PERIOD_MS=${SCRAPER_RATE_LIMIT_PERIOD_MS:-60000}
      - SCRAPER_PROXY_ENABLED=${SCRAPER_PROXY_ENABLED:-false}
      - SCRAPER_PROXY_URL=${SCRAPER_PROXY_URL:-}
      - SCRAPER_USER_AGENT=${SCRAPER_USER_AGENT:-Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36}
      - SCRAPER_TIMEOUT_MS=${SCRAPER_TIMEOUT_MS:-30000}
      - SCRAPER_MAX_RETRIES=${SCRAPER_MAX_RETRIES:-3}
      # Data persistence
      - DATA_DIR=${DATA_DIR:-/app/data}
    volumes:
      - app-data:/app/data
    networks:
      - fooddealsniper
    healthcheck:
      test: ['CMD', 'node', '-e', "require('http').get('http://localhost:4000/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 10s

  frontend:
    image: nginx:alpine
    restart: unless-stopped
    ports:
      - '${FRONTEND_PORT:-80}:80'
    volumes:
      - ./packages/frontend/dist:/usr/share/nginx/html:ro
      - ./nginx.conf:/etc/nginx/conf.d/default.conf:ro
    depends_on:
      - backend
    networks:
      - fooddealsniper
    healthcheck:
      test: ['CMD', 'wget', '-q', '--spider', 'http://localhost:80']
      interval: 30s
      timeout: 3s
      retries: 3

volumes:
  app-data:
    driver: local

networks:
  fooddealsniper:
    driver: bridge
